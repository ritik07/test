{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing, Training, and Deploying a TensorFlow model on Google Cloud Platform (using CloudShell and Cloud AI Platform)\n",
    "\n",
    "In this notebook, we will develop a Keras model to predict flight delays using TensorFlow 2.0 as the backend. Unlike [flights_model_tf2.ipynb](flights_model_tf2.ipynb), we will use bash commands so that these can be run from CloudShell. We will also deploy to Cloud AI Platform so that the model can be executed in a serverless way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables\n",
    "\n",
    "I'm doing this for the notebook. In CloudShell, you'd do:\n",
    "<pre>\n",
    "export PROJECT=cloud-training-demos\n",
    "</pre>\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out different functions in the model\n",
    "\n",
    "Reading lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=\"$PWD/flights\"\n",
    "python3 -m trainer.task --bucket $BUCKET --train_batch_size=3 --func=read_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding average label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=\"$PWD/flights\"\n",
    "python3 -m trainer.task --bucket $BUCKET --num_examples=100 --func=find_average_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=\"$PWD/flights\"\n",
    "gsutil -m rm -rf gs://$BUCKET/flights/trained_model\n",
    "python3 -m trainer.task --bucket $BUCKET --num_examples=1000 --func=linear\n",
    "\n",
    "gsutil ls gs://$BUCKET/flights/trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wide-and-deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=\"$PWD/flights\"\n",
    "gsutil -m rm -rf gs://$BUCKET/flights/trained_model\n",
    "python3 -m trainer.task --bucket $BUCKET --num_examples=1000 --func=wide_deep\n",
    "\n",
    "gsutil ls gs://$BUCKET/flights/trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(gsutil ls gs://$BUCKET/flights/trained_model/export | tail -1)\n",
    "echo $model_dir\n",
    "saved_model_cli show --tag_set serve --signature_def serving_default --dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Docker image\n",
    "\n",
    "In this section, I use a Docker container to capture my development environment. A better alternative is to directly submit the Python package, but I'm writing this before TensorFlow 2.0 is officially released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flights/Dockerfile\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu\n",
    "\n",
    "#RUN python3 -m pip install --upgrade --quiet tf-nightly-2.0-preview\n",
    "RUN python3 -m pip install --upgrade --quiet cloudml-hypertune\n",
    "\n",
    "COPY . /flights\n",
    "ENV PYTHONPATH ${PYTHONPATH}:/flights\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flights/push_docker.sh\n",
    "export PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")\n",
    "export IMAGE_REPO_NAME=flights_training_container\n",
    "#export IMAGE_TAG=$(date +%Y%m%d_%H%M%S)\n",
    "#export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME\n",
    "\n",
    "echo \"Building  $IMAGE_URI\"\n",
    "docker build -f Dockerfile -t $IMAGE_URI ./\n",
    "echo \"Pushing $IMAGE_URI\"\n",
    "docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> If you get a permissions/stat error when running push_docker.sh from Notebooks, do it from CloudShell:\n",
    "\n",
    "Open CloudShell on the GCP Console\n",
    "\n",
    "<pre>\n",
    "git clone https://github.com/GoogleCloudPlatform/data-science-on-gcp\n",
    "git checkout tf2\n",
    "cd data-science-on-gcp/09_cloudml/flights\n",
    "bash push_docker.sh\n",
    "</pre>\n",
    "This step takes 5-10 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd flights\n",
    "bash push_docker.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on full dataset\n",
    "\n",
    "Submit the Docker image to Cloud AI Platform Training and have it process full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "JOBID=flights_$(date +%Y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf gs://$BUCKET/flights/trained_model\n",
    "\n",
    "#IMAGE=gcr.io/deeplearning-platform-release/tf2-cpu\n",
    "IMAGE=gcr.io/$PROJECT/flights_training_container\n",
    "\n",
    "gcloud beta ai-platform jobs submit training $JOBID \\\n",
    "   --staging-bucket=gs://$BUCKET  --region=$REGION \\\n",
    "   --master-image-uri=$IMAGE \\\n",
    "   --master-machine-type=n1-standard-4 --scale-tier=CUSTOM \\\n",
    "   -- \\\n",
    "   --bucket=$BUCKET --num_examples=1000000 --func=wide_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final validation RMSE was 0.214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "model_dir=$(gsutil ls gs://$BUCKET/flights/trained_model/export | tail -1)\n",
    "echo $model_dir\n",
    "saved_model_cli show --tag_set serve --signature_def serving_default --dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "JOBID=flights_$(date +%Y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf gs://$BUCKET/flights/trained_model\n",
    "\n",
    "#IMAGE=gcr.io/deeplearning-platform-release/tf2-cpu\n",
    "IMAGE=gcr.io/$PROJECT/flights_training_container\n",
    "\n",
    "gcloud beta ai-platform jobs submit training $JOBID \\\n",
    "   --staging-bucket=gs://$BUCKET  --region=$REGION \\\n",
    "   --master-image-uri=$IMAGE \\\n",
    "   --config=hyperparam.yaml \\\n",
    "   -- \\\n",
    "   --bucket=$BUCKET --num_examples=100000 --func=wide_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=flights\n",
    "VERSION_NAME=tf2\n",
    "BEST_MODEL=\"15/\"   # use an empty string if you didn't do hyperparam tuning\n",
    "EXPORT_PATH=$(gsutil ls gs://$BUCKET/flights/trained_model/${BEST_MODEL}export | tail -1)\n",
    "echo $EXPORT_PATH\n",
    "\n",
    "if [[ $(gcloud ai-platform models list --format='value(name)' | grep $MODEL_NAME) ]]; then\n",
    "    echo \"$MODEL_NAME already exists\"\n",
    "else\n",
    "    # create model\n",
    "    echo \"Creating $MODEL_NAME\"\n",
    "    gcloud ai-platform models create --regions=$REGION $MODEL_NAME\n",
    "fi\n",
    "\n",
    "if [[ $(gcloud ai-platform versions list --model $MODEL_NAME --format='value(name)' | grep $VERSION_NAME) ]]; then\n",
    "    echo \"Deleting already existing $MODEL_NAME:$VERSION_NAME ... \"\n",
    "    gcloud ai-platform versions delete --quiet --model=$MODEL_NAME $VERSION_NAME\n",
    "    echo \"Please run this cell again if you don't see a Creating message ... \"\n",
    "    sleep 10\n",
    "fi\n",
    "\n",
    "# create model\n",
    "echo \"Creating $MODEL_NAME:$VERSION_NAME\"\n",
    "gcloud ai-platform versions create --model=$MODEL_NAME $VERSION_NAME --async \\\n",
    "       --framework=tensorflow --python-version=3.5 --runtime-version=1.14 \\\n",
    "       --origin=$EXPORT_PATH --staging-bucket=gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example_input.json\n",
    "{\"dep_delay\": 14.0, \"taxiout\": 13.0, \"distance\": 319.0, \"avg_dep_delay\": 25.863039, \"avg_arr_delay\": 27.0, \"carrier\": \"WN\", \"dep_lat\": 32.84722, \"dep_lon\": -96.85167, \"arr_lat\": 31.9425, \"arr_lon\": -102.20194, \"origin\": \"DAL\", \"dest\": \"MAF\"}\n",
    "{\"dep_delay\": -9.0, \"taxiout\": 21.0, \"distance\": 301.0, \"avg_dep_delay\": 41.050808, \"avg_arr_delay\": -7.0, \"carrier\": \"EV\", \"dep_lat\": 29.984444, \"dep_lon\": -95.34139, \"arr_lat\": 27.544167, \"arr_lon\": -99.46167, \"origin\": \"IAH\", \"dest\": \"LRD\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED\n",
      "[0.7853261828422546]\n",
      "[0.9965983033180237]\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict --model=flights --version=tf2 --json-instances=example_input.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
